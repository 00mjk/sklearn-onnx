.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_gpr.py>`     to download the full example code or to run this example in your browser via Binder
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_plot_gpr.py:


.. _l-gpr-example:

Discrepencies with GaussianProcessorRegressor: use of double
============================================================

The `GaussianProcessRegressor
<https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.
GaussianProcessRegressor.html>`_ involves
many matrix operations which may requires double
precisions. *sklearn-onnx* is using single floats by default
but for this particular model, it is better to use double.
Let's see how to create an ONNX file using doubles.

.. contents::
    :local:

Train a model
+++++++++++++

A very basic example using *GaussianProcessRegressor*
on the Boston dataset.


.. code-block:: default

    import pprint
    import numpy
    import sklearn
    from sklearn.datasets import load_boston
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import DotProduct, RBF
    from sklearn.model_selection import train_test_split
    import onnx
    import onnxruntime as rt
    import skl2onnx
    from skl2onnx.common.data_types import FloatTensorType, DoubleTensorType
    from skl2onnx import convert_sklearn

    bost = load_boston()
    X, y = bost.data, bost.target
    X_train, X_test, y_train, y_test = train_test_split(X, y)
    gpr = GaussianProcessRegressor(DotProduct() + RBF(), alpha=1.)
    gpr.fit(X_train, y_train)
    print(gpr)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    GaussianProcessRegressor(alpha=1.0,
                             kernel=DotProduct(sigma_0=1) + RBF(length_scale=1))




First attempt to convert a model into ONNX
++++++++++++++++++++++++++++++++++++++++++

The documentation suggests the following way to
convert a model into ONNX.


.. code-block:: default


    initial_type = [('X', FloatTensorType([None, X_train.shape[1]]))]
    onx = convert_sklearn(gpr, initial_types=initial_type,
                          target_opset=12)

    sess = rt.InferenceSession(onx.SerializeToString())
    try:
        pred_onx = sess.run(
            None, {'X': X_test.astype(numpy.float32)})[0]
    except RuntimeError as e:
        print(str(e))








Second attempt: variable dimensions
+++++++++++++++++++++++++++++++++++

Unfortunately, even though the conversion
went well, the runtime fails to compute the prediction.
The previous snippet of code imposes fixed dimension
on the input and therefore let the runtime assume
every node output has outputs with fixed dimensions
And that's not the case for this model.
We need to disable these checkings by replacing
the fixed dimensions by an empty value.
(see next line).


.. code-block:: default


    initial_type = [('X', FloatTensorType([None, None]))]
    onx = convert_sklearn(gpr, initial_types=initial_type,
                          target_opset=12)

    sess = rt.InferenceSession(onx.SerializeToString())
    pred_onx = sess.run(
        None, {'X': X_test.astype(numpy.float32)})[0]

    pred_skl = gpr.predict(X_test)
    print(pred_skl[:10])
    print(pred_onx[0, :10])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [19.31167715 16.50846442 23.49000142 18.51457635  8.42066095 26.41539942
     29.60405739 13.33343228 28.68116695 24.36466454]
    [18.125   16.59375 23.      18.53125  9.78125 24.9375  30.46875 11.03125
     28.      23.125  ]




The differences seems quite important.
Let's confirm that by looking at the biggest
differences.


.. code-block:: default


    diff = numpy.sort(numpy.abs(numpy.squeeze(pred_skl) -
                                numpy.squeeze(pred_onx)))[-5:]
    print(diff)
    print('min(Y)-max(Y):', min(y_test), max(y_test))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [2.773486   2.99130079 3.12749888 3.20009654 3.42657914]
    min(Y)-max(Y): 7.0 50.0




Third attempt: use of double
++++++++++++++++++++++++++++

The model uses a couple of matrix computations
and matrices have coefficients with very different
order of magnitude. It is difficult to approximate
the prediction made with scikit-learn if the converted
model sticks to float. Double precision is needed.

The previous code requires two changes. The first
one indicates that inputs are now of type
``DoubleTensorType``. The second change
is the extra parameter ``dtype=numpy.float64``
tells the conversion function that every real
constant matrix such as the trained coefficients
will be dumped as doubles and not as floats anymore.


.. code-block:: default


    initial_type = [('X', DoubleTensorType([None, None]))]
    onx64 = convert_sklearn(gpr, initial_types=initial_type,
                            target_opset=12)

    sess64 = rt.InferenceSession(onx64.SerializeToString())
    pred_onx64 = sess64.run(None, {'X': X_test})[0]

    print(pred_onx64[0, :10])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [19.31167715 16.50846441 23.49000141 18.51457635  8.42066094 26.41539942
     29.60405739 13.33343229 28.68116695 24.36466454]




The new differences look much better.


.. code-block:: default


    diff = numpy.sort(numpy.abs(numpy.squeeze(pred_skl) -
                                numpy.squeeze(pred_onx64)))[-5:]
    print(diff)
    print('min(Y)-max(Y):', min(y_test), max(y_test))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [1.15251169e-08 1.26310624e-08 1.38534233e-08 1.60071068e-08
     2.07801349e-08]
    min(Y)-max(Y): 7.0 50.0




Size increase
+++++++++++++

As a result, the ONNX model is almost twice bigger
because every coefficient is stored as double and
and not as floats anymore.


.. code-block:: default


    size32 = len(onx.SerializeToString())
    size64 = len(onx64.SerializeToString())
    print("ONNX with floats:", size32)
    print("ONNX with doubles:", size64)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ONNX with floats: 42723
    ONNX with doubles: 83727




return_std=True
+++++++++++++++

`GaussianProcessRegressor <https://scikit-learn.org/stable/modules/
generated/sklearn.gaussian_process.GaussianProcessRegressor.html>`_
is one model which defined additional parameter to the predict function.
If call with ``return_std=True``, the class returns one more results
and that needs to be reflected into the generated ONNX graph.
The converter needs to know that an extended graph is required.
That's done through the option mechanism
(see :ref:`l-conv-options`).


.. code-block:: default


    initial_type = [('X', DoubleTensorType([None, None]))]
    options = {GaussianProcessRegressor: {'return_std': True}}
    try:
        onx64_std = convert_sklearn(gpr, initial_types=initial_type,
                                    options=options, target_opset=12)
    except RuntimeError as e:
        print(e)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    The method *predict* must be called once with parameter return_std=True to compute internal variables. They cannot be computed here as the same operation (matrix inversion) produces too many discrepencies if done with single floats than double floats.




This error highlights the fact that the *scikit-learn*
computes internal variables on first call to method predict.
The converter needs them to be initialized by calling method
predict at least once and then converting again.


.. code-block:: default


    gpr.predict(X_test[:1], return_std=True)
    onx64_std = convert_sklearn(gpr, initial_types=initial_type,
                                options=options, target_opset=12)

    sess64_std = rt.InferenceSession(onx64_std.SerializeToString())
    pred_onx64_std = sess64_std.run(None, {'X': X_test[:5]})

    pprint.pprint(pred_onx64_std)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [array([[19.31167715, 16.50846441, 23.49000141, 18.51457635,  8.42066094]]),
     array([0.79381404, 1.04565067, 1.01796157, 1.04859644, 0.95063572])]




Let's compare with *scikit-learn* prediction.


.. code-block:: default


    pprint.pprint(gpr.predict(X_test[:5], return_std=True))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (array([19.31167715, 16.50846442, 23.49000142, 18.51457635,  8.42066094]),
     array([0.79360762, 1.04569317, 1.01824567, 1.04841356, 0.95047268]))




It looks good. Let's do a better checks.


.. code-block:: default



    pred_onx64_std = sess64_std.run(None, {'X': X_test})
    pred_std = gpr.predict(X_test, return_std=True)


    diff = numpy.sort(numpy.abs(numpy.squeeze(pred_onx64_std[1]) -
                                numpy.squeeze(pred_std[1])))[-5:]
    print(diff)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [0.00086765 0.00097114 0.00107633 0.00122894 0.00155228]




There are some discrepencies but it seems reasonable.

**Versions used for this example**


.. code-block:: default


    print("numpy:", numpy.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", rt.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    numpy: 1.19.1
    scikit-learn: 0.23.2
    onnx:  1.7.0
    onnxruntime:  1.4.0
    skl2onnx:  1.7.1





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.997 seconds)


.. _sphx_glr_download_auto_examples_plot_gpr.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: /../../cus/lib/python3.7/site-packages/sphinx_gallery/_static/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/microsoft/skl2onnx/master?urlpath=lab/tree/notebooks/auto_examples/plot_gpr.ipynb
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_gpr.py <plot_gpr.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_gpr.ipynb <plot_gpr.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
