.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_plot_backend.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_backend.py:


.. _l-example-backend-api:

ONNX Runtime Backend for ONNX
=============================

.. index:: backend

*ONNX Runtime* extends the
`onnx backend API <https://github.com/onnx/onnx/blob/master/docs/
ImplementingAnOnnxBackend.md>`_
to run predictions using this runtime.
Let's use the API to compute the prediction
of a simple logistic regression model.

.. code-block:: default

    import skl2onnx
    import onnxruntime
    import onnx
    import sklearn
    import numpy
    from onnxruntime import get_device
    import numpy as np
    from onnxruntime import datasets
    import onnxruntime.backend as backend
    from onnx import load

    name = datasets.get_example("logreg_iris.onnx")
    model = load(name)

    rep = backend.prepare(model, 'CPU')
    x = np.array([[-1.0, -2.0, 5.0, 6.0],
                  [-1.0, -2.0, -3.0, -4.0],
                  [-1.0, -2.0, 7.0, 8.0]],
                 dtype=np.float32)
    label, proba = rep.run(x)
    print("label={}".format(label))
    print("probabilities={}".format(proba))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    label=[2 0 2]
    probabilities=[{0: 2.6998525637367266e-10, 1: 6.870588009633138e-08, 2: 0.9999999403953552}, {0: 0.9999974370002747, 1: 2.5871079287753673e-06, 2: 6.67297780009494e-20}, {0: 7.274464534807741e-17, 1: 1.7157689114963293e-12, 2: 1.0}]


The device depends on how the package was compiled,
GPU or CPU.


.. code-block:: default

    print(get_device())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    CPU


The backend can also directly load the model
without using *onnx*.


.. code-block:: default


    rep = backend.prepare(name, 'CPU')
    x = np.array([[-1.0, -2.0, -3.0, -4.0],
                  [-1.0, -2.0, -3.0, -4.0],
                  [-1.0, -2.0, -3.0, -4.0]],
                 dtype=np.float32)
    label, proba = rep.run(x)
    print("label={}".format(label))
    print("probabilities={}".format(proba))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    label=[0 0 0]
    probabilities=[{0: 0.9999974370002747, 1: 2.5871079287753673e-06, 2: 6.67297780009494e-20}, {0: 0.9999974370002747, 1: 2.5871079287753673e-06, 2: 6.67297780009494e-20}, {0: 0.9999974370002747, 1: 2.5871079287753673e-06, 2: 6.67297780009494e-20}]


The backend API is implemented by other frameworks
and makes it easier to switch between multiple runtimes
with the same API.

**Versions used for this example**


.. code-block:: default


    print("numpy:", numpy.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", onnxruntime.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    numpy: 1.17.0
    scikit-learn: 0.22.dev0
    onnx:  1.6.32
    onnxruntime:  1.0.991
    skl2onnx:  1.6.0



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.106 seconds)


.. _sphx_glr_download_auto_examples_plot_backend.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_backend.py <plot_backend.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_backend.ipynb <plot_backend.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
