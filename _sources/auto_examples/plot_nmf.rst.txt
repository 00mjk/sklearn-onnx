.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_plot_nmf.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_nmf.py:


Custom Operator for NMF Decomposition
=====================================

`NMF <https://scikit-learn.org/stable/modules/generated/
sklearn.decomposition.NMF.html>`_ factorizes an input matrix
into two matrices *W, H* of rank *k* so that :math:`WH \sim M``.
:math:`M=(m_{ij})` may be a binary matrix where *i* is a user
and *j* a product he bought. The prediction
function depends on whether or not the user needs a
recommandation for an existing user or a new user.
This example addresses the first case.

The second case is more complex as it theoretically
requires the estimation of a new matrix *W* with a
gradient descent.

.. contents::
    :local:

Building a simple model
+++++++++++++++++++++++

.. code-block:: default


    import os
    import skl2onnx
    import onnxruntime
    import sklearn
    from sklearn.decomposition import NMF
    import numpy as np
    import matplotlib.pyplot as plt
    from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer
    import onnx
    from skl2onnx.algebra.onnx_ops import (
        OnnxArrayFeatureExtractor, OnnxMul, OnnxReduceSum)
    from skl2onnx.common.data_types import FloatTensorType
    from onnxruntime import InferenceSession


    mat = np.array([[1, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0],
                    [1, 0, 0, 0], [1, 0, 0, 0]], dtype=np.float64)
    mat[:mat.shape[1], :] += np.identity(mat.shape[1])

    mod = NMF(n_components=2)
    W = mod.fit_transform(mat)
    H = mod.components_
    pred = mod.inverse_transform(W)

    print("original predictions")
    exp = []
    for i in range(mat.shape[0]):
        for j in range(mat.shape[1]):
            exp.append((i, j, pred[i, j]))

    print(exp)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    original predictions
    [(0, 0, 1.894026723010214), (0, 1, 0.10917444511058898), (0, 2, 0.3072496472670789), (0, 3, 0.3072496472670789), (1, 0, 1.0146841034217697), (1, 1, 0.984872329246054), (1, 2, 0.0), (1, 3, 0.0), (2, 0, 1.106628446917871), (2, 1, 0.0), (2, 2, 0.19085159419807027), (2, 3, 0.19085159419807027), (3, 0, 1.106628446917871), (3, 1, 0.0), (3, 2, 0.19085159419807027), (3, 3, 0.19085159419807027), (4, 0, 0.947013361505107), (4, 1, 0.05458722255529449), (4, 2, 0.15362482363353944), (4, 3, 0.15362482363353944)]


Let's rewrite the prediction in a way it is closer
to the function we need to convert into ONNX.


.. code-block:: default



    def predict(W, H, row_index, col_index):
        return np.dot(W[row_index, :], H[:, col_index])


    got = []
    for i in range(mat.shape[0]):
        for j in range(mat.shape[1]):
            got.append((i, j, predict(W, H, i, j)))

    print(got)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(0, 0, 1.894026723010214), (0, 1, 0.10917444511058898), (0, 2, 0.3072496472670789), (0, 3, 0.3072496472670789), (1, 0, 1.0146841034217697), (1, 1, 0.984872329246054), (1, 2, 0.0), (1, 3, 0.0), (2, 0, 1.106628446917871), (2, 1, 0.0), (2, 2, 0.19085159419807027), (2, 3, 0.19085159419807027), (3, 0, 1.106628446917871), (3, 1, 0.0), (3, 2, 0.19085159419807027), (3, 3, 0.19085159419807027), (4, 0, 0.947013361505107), (4, 1, 0.05458722255529449), (4, 2, 0.15362482363353944), (4, 3, 0.15362482363353944)]


Conversion into ONNX
++++++++++++++++++++

There is no implemented converter for
`NMF <https://scikit-learn.org/stable/modules/generated/
sklearn.decomposition.NMF.html>`_ as the function we plan
to convert is not transformer or a predictor.
The following converter does not need to be registered,
it just creates an ONNX graph equivalent to function
*predict* implemented above.


.. code-block:: default



    def nmf_to_onnx(W, H):
        """
        The function converts a NMF described by matrices
        *W*, *H* (*WH* approximate training data *M*).
        into a function which takes two indices *(i, j)*
        and returns the predictions for it. It assumes
        these indices applies on the training data.
        """
        col = OnnxArrayFeatureExtractor(H, 'col')
        row = OnnxArrayFeatureExtractor(W.T, 'row')
        dot = OnnxMul(col, row)
        res = OnnxReduceSum(dot, output_names="rec")
        indices_type = np.array([0], dtype=np.int64)
        onx = res.to_onnx(inputs={'col': indices_type,
                                  'row': indices_type},
                          outputs=[('rec', FloatTensorType((None, 1)))])
        return onx


    model_onnx = nmf_to_onnx(W, H)
    print(model_onnx)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ir_version: 6
    producer_name: "skl2onnx"
    producer_version: "1.5.2"
    domain: "ai.onnx"
    model_version: 0
    graph {
      node {
        input: "Ar_ArrayFeatureExtractorcst"
        input: "col"
        output: "Ar_Z0"
        name: "Ar_ArrayFeatureExtractor"
        op_type: "ArrayFeatureExtractor"
        domain: "ai.onnx.ml"
      }
      node {
        input: "Ar_ArrayFeatureExtractorcst1"
        input: "row"
        output: "Ar_Z01"
        name: "Ar_ArrayFeatureExtractor1"
        op_type: "ArrayFeatureExtractor"
        domain: "ai.onnx.ml"
      }
      node {
        input: "Ar_Z0"
        input: "Ar_Z01"
        output: "Mu_C0"
        name: "Mu_Mul"
        op_type: "Mul"
        domain: ""
      }
      node {
        input: "Mu_C0"
        output: "rec"
        name: "Re_ReduceSum"
        op_type: "ReduceSum"
        domain: ""
      }
      name: "OnnxReduceSum"
      initializer {
        dims: 2
        dims: 4
        data_type: 1
        float_data: 1.6038050651550293
        float_data: 0.0
        float_data: 0.2765957713127136
        float_data: 0.2765957713127136
        float_data: 0.6532432436943054
        float_data: 0.634050726890564
        float_data: 0.0
        float_data: 0.0
        name: "Ar_ArrayFeatureExtractorcst"
      }
      initializer {
        dims: 2
        dims: 5
        data_type: 1
        float_data: 1.110825538635254
        float_data: 0.0
        float_data: 0.6900018453598022
        float_data: 0.6900018453598022
        float_data: 0.555412769317627
        float_data: 0.17218567430973053
        float_data: 1.5533021688461304
        float_data: 0.0
        float_data: 0.0
        float_data: 0.08609283715486526
        name: "Ar_ArrayFeatureExtractorcst1"
      }
      input {
        name: "col"
        type {
          tensor_type {
            elem_type: 7
            shape {
              dim {
              }
            }
          }
        }
      }
      input {
        name: "row"
        type {
          tensor_type {
            elem_type: 7
            shape {
              dim {
              }
            }
          }
        }
      }
      output {
        name: "rec"
        type {
          tensor_type {
            elem_type: 1
            shape {
              dim {
              }
              dim {
                dim_value: 1
              }
            }
          }
        }
      }
    }
    opset_import {
      domain: "ai.onnx.ml"
      version: 11
    }
    opset_import {
      domain: ""
      version: 11
    }


Let's compute prediction with it.


.. code-block:: default


    sess = InferenceSession(model_onnx.SerializeToString())


    def predict_onnx(sess, row_indices, col_indices):
        res = sess.run(None,
                       {'col': col_indices,
                        'row': row_indices})
        return res


    onnx_preds = []
    for i in range(mat.shape[0]):
        for j in range(mat.shape[1]):
            row_indices = np.array([i], dtype=np.int64)
            col_indices = np.array([j], dtype=np.int64)
            pred = predict_onnx(sess, row_indices, col_indices)[0]
            onnx_preds.append((i, j, pred[0, 0]))

    print(onnx_preds)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(0, 0, 1.8940268), (0, 1, 0.10917445), (0, 2, 0.30724964), (0, 3, 0.30724964), (1, 0, 1.0146842), (1, 1, 0.98487234), (1, 2, 0.0), (1, 3, 0.0), (2, 0, 1.1066284), (2, 1, 0.0), (2, 2, 0.1908516), (2, 3, 0.1908516), (3, 0, 1.1066284), (3, 1, 0.0), (3, 2, 0.1908516), (3, 3, 0.1908516), (4, 0, 0.9470134), (4, 1, 0.054587226), (4, 2, 0.15362482), (4, 3, 0.15362482)]


The ONNX graph looks like the following.


.. code-block:: default

    pydot_graph = GetPydotGraph(
        model_onnx.graph, name=model_onnx.graph.name,
        rankdir="TB", node_producer=GetOpNodeProducer("docstring"))
    pydot_graph.write_dot("graph_nmf.dot")
    os.system('dot -O -Tpng graph_nmf.dot')
    image = plt.imread("graph_nmf.dot.png")
    plt.imshow(image)
    plt.axis('off')




.. image:: /auto_examples/images/sphx_glr_plot_nmf_001.png
    :class: sphx-glr-single-img




**Versions used for this example**


.. code-block:: default


    print("numpy:", np.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", onnxruntime.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    numpy: 1.17.0
    scikit-learn: 0.22.dev0
    onnx:  1.6.32
    onnxruntime:  1.0.991
    skl2onnx:  1.5.2



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.449 seconds)


.. _sphx_glr_download_auto_examples_plot_nmf.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_nmf.py <plot_nmf.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_nmf.ipynb <plot_nmf.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
