.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorial_plot_gbegin_transfer_learning.py>`     to download the full example code or to run this example in your browser via Binder
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_tutorial_plot_gbegin_transfer_learning.py:


Transfer Learning with ONNX
===========================

.. index:: transfer learning, deep learning

Transfer learning is common with deep learning.
A deep learning model is used as preprocessing before
the output is sent to a final classifier or regressor.
It is not quite easy in this case to mix framework,
:epkg:`scikit-learn` with :epkg:`pytorch`
(or :epkg:`skorch`), the Keras API for Tensorflow,
`tf.keras.wrappers.scikit_learn
<https://www.tensorflow.org/api_docs/python/tf/
keras/wrappers/scikit_learn>`_. Every combination
requires work. ONNX reduces the number of platforms to
support. Once the model is converted into ONNX,
it can be inserted in any :epkg:`scikit-learn` pipeline.

.. contents::
    :local:

Retrieve and load a model
+++++++++++++++++++++++++

We download one model from the :epkg:`ONNX Zoo` but the model
could be trained and produced by another converter library.


.. code-block:: default

    from io import BytesIO
    import onnx
    from mlprodict.sklapi import OnnxTransformer
    from sklearn.decomposition import PCA
    from sklearn.pipeline import Pipeline
    from mlinsights.plotting.gallery import plot_gallery_images
    import matplotlib.pyplot as plt
    from skl2onnx.tutorial.imagenet_classes import class_names
    import numpy
    from PIL import Image
    from onnxruntime import InferenceSession
    import os
    import urllib.request


    def download_file(url, name, min_size):
        if not os.path.exists(name):
            print("download '%s'" % url)
            with urllib.request.urlopen(url) as u:
                content = u.read()
            if len(content) < min_size:
                raise RuntimeError(
                    "Unable to download '{}' due to\n{}".format(
                        url, content))
            print("downloaded %d bytes." % len(content))
            with open(name, "wb") as f:
                f.write(content)
        else:
            print("'%s' already downloaded" % name)


    model_name = "squeezenet1.1-7.onnx"
    url_name = ("https://github.com/onnx/models/raw/master/vision/"
                "classification/squeezenet/model")
    url_name += "/" + model_name
    download_file(url_name, model_name, 100000)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    'squeezenet1.1-7.onnx' already downloaded




Loading the ONNX file and use it on one image.


.. code-block:: default


    sess = InferenceSession(model_name)

    for inp in sess.get_inputs():
        print(inp)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    NodeArg(name='data', type='tensor(float)', shape=[1, 3, 224, 224])




The model expects a series of images of size
`[3, 224, 224]`.

Classifying an image
++++++++++++++++++++


.. code-block:: default


    url = ("https://upload.wikimedia.org/wikipedia/commons/d/d2/"
           "East_Coker_elm%2C_2.jpg")
    img = "East_Coker_elm.jpg"
    download_file(url, img, 100000)

    im0 = Image.open(img)
    im = im0.resize((224, 224))
    # im.show()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    'East_Coker_elm.jpg' already downloaded




Image to numpy and predection.


.. code-block:: default



    def im2array(im):
        X = numpy.asarray(im)
        X = X.transpose(2, 0, 1)
        X = X.reshape(1, 3, 224, 224)
        return X


    X = im2array(im)
    out = sess.run(None, {'data': X.astype(numpy.float32)})
    out = out[0]

    print(out[0, :5])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [145.59029   55.140186  61.21884   46.509796  38.375053]




Interpretation


.. code-block:: default



    res = list(sorted((r, class_names[i]) for i, r in enumerate(out[0])))
    print(res[-5:])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(206.34744, 'Samoyed, Samoyede'), (212.19128, 'park bench'), (226.09026, 'lakeside, lakeshore'), (232.6838, 'fountain'), (257.58295, 'geyser')]




Classifying more images
+++++++++++++++++++++++

The initial image is rotated,
the answer is changing.


.. code-block:: default


    angles = [a * 2. for a in range(-6, 6)]
    imgs = [(angle, im0.rotate(angle).resize((224, 224)))
            for angle in angles]


    def classify(imgs):
        labels = []
        for angle, img in imgs:
            X = im2array(img)
            probs = sess.run(None, {'data': X.astype(numpy.float32)})[0]
            pl = list(sorted(
                ((r, class_names[i]) for i, r in enumerate(probs[0])),
                reverse=True))
            labels.append((angle, pl))
        return labels


    climgs = classify(imgs)
    for angle, res in climgs:
        print("angle={} - {}".format(angle, res[:5]))


    plot_gallery_images([img[1] for img in imgs],
                        [img[1][0][1][:15] for img in climgs])




.. image:: /auto_tutorial/images/sphx_glr_plot_gbegin_transfer_learning_001.png
    :alt: plot gbegin transfer learning
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    angle=-12.0 - [(247.47911, 'obelisk'), (238.36127, 'car mirror'), (235.49062, 'flagpole, flagstaff'), (231.89911, 'window screen'), (231.2254, 'picket fence, paling')]
    angle=-10.0 - [(254.36493, 'car mirror'), (251.50365, 'obelisk'), (235.37222, 'groom, bridegroom'), (234.33972, 'picket fence, paling'), (231.73546, 'church, church building')]
    angle=-8.0 - [(235.58696, 'obelisk'), (225.82468, 'car mirror'), (225.36705, 'picket fence, paling'), (222.45569, 'fountain'), (221.71461, 'groom, bridegroom')]
    angle=-6.0 - [(265.6314, 'geyser'), (244.20534, 'obelisk'), (239.99597, 'fountain'), (227.56766, 'pedestal, plinth, footstall'), (226.1277, 'Great Pyrenees')]
    angle=-4.0 - [(287.70456, 'geyser'), (255.60565, 'fountain'), (238.06335, 'obelisk'), (223.45006, 'church, church building'), (222.72023, 'beacon, lighthouse, beacon light, pharos')]
    angle=-2.0 - [(267.526, 'geyser'), (252.10635, 'fountain'), (214.55492, 'obelisk'), (213.99307, 'mobile home, manufactured home'), (213.1479, 'flagpole, flagstaff')]
    angle=0.0 - [(257.58295, 'geyser'), (232.6838, 'fountain'), (226.09026, 'lakeside, lakeshore'), (212.19128, 'park bench'), (206.34744, 'Samoyed, Samoyede')]
    angle=2.0 - [(222.2733, 'geyser'), (213.52834, 'fountain'), (212.09451, 'obelisk'), (198.55171, 'beacon, lighthouse, beacon light, pharos'), (198.03336, 'picket fence, paling')]
    angle=4.0 - [(221.87326, 'geyser'), (210.52614, 'fountain'), (207.54575, 'American egret, great white heron, Egretta albus'), (202.08311, 'obelisk'), (199.36952, 'Great Pyrenees')]
    angle=6.0 - [(230.44984, 'American egret, great white heron, Egretta albus'), (217.58267, 'fountain'), (213.00862, 'groom, bridegroom'), (210.03789, 'flagpole, flagstaff'), (209.36566, 'swimming trunks, bathing trunks')]
    angle=8.0 - [(255.28929, 'American egret, great white heron, Egretta albus'), (223.92719, 'golf ball'), (223.90028, 'groom, bridegroom'), (223.26468, 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita'), (218.02217, 'swimming trunks, bathing trunks')]
    angle=10.0 - [(244.81952, 'solar dish, solar collector, solar furnace'), (239.62137, 'flagpole, flagstaff'), (234.68286, 'picket fence, paling'), (230.87357, 'car mirror'), (222.45735, 'screen, CRT screen')]

    array([[<AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>],
           [<AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>],
           [<AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>]],
          dtype=object)



Transfer learning in a pipeline
+++++++++++++++++++++++++++++++

The proposed transfer learning consists
using a PCA to projet the probabilities
on a graph.


.. code-block:: default



    with open(model_name, 'rb') as f:
        model_bytes = f.read()

    pipe = Pipeline(steps=[
        ('deep', OnnxTransformer(
            model_bytes, runtime='onnxruntime1', change_batch_size=0)),
        ('pca', PCA(2))
    ])

    X_train = numpy.vstack(
        [im2array(img) for _, img in imgs]).astype(numpy.float32)
    pipe.fit(X_train)

    proj = pipe.transform(X_train)
    print(proj)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [[-672.64307  -214.14084 ]
     [-568.29     -202.07352 ]
     [-343.8824    -86.668755]
     [ -17.452633 -162.05714 ]
     [ 364.08597  -150.72943 ]
     [ 596.82495   -86.63826 ]
     [ 918.74176   -37.703796]
     [ 504.90875   129.27518 ]
     [ 307.3957    158.65074 ]
     [-129.88425   127.99908 ]
     [-456.66077   344.0549  ]
     [-503.14392   180.03185 ]]




Graph for the PCA
-----------------


.. code-block:: default


    fig, ax = plt.subplots(1, 1, figsize=(5, 5))
    ax.plot(proj[:, 0], proj[:, 1], 'o')
    ax.set_title("Projection of classification probabilities")
    text = ["%1.0f-%s" % (el[0], el[1][0][1]) for el in climgs]
    for label, x, y in zip(text, proj[:, 0], proj[:, 1]):
        ax.annotate(
            label, xy=(x, y), xytext=(-10, 10), fontsize=8,
            textcoords='offset points', ha='right', va='bottom',
            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),
            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))




.. image:: /auto_tutorial/images/sphx_glr_plot_gbegin_transfer_learning_002.png
    :alt: Projection of classification probabilities
    :class: sphx-glr-single-img





Remove one layer at the end
---------------------------

The last is often removed before the model is
inserted in a pipeline. Let's see how to do that.
First, we need the list of output for every node.


.. code-block:: default



    model_onnx = onnx.load(BytesIO(model_bytes))
    outputs = []
    for node in model_onnx.graph.node:
        print(node.name, node.output)
        outputs.extend(node.output)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    squeezenet0_conv0_fwd ['squeezenet0_conv0_fwd']
    squeezenet0_relu0_fwd ['squeezenet0_relu0_fwd']
    squeezenet0_pool0_fwd ['squeezenet0_pool0_fwd']
    squeezenet0_conv1_fwd ['squeezenet0_conv1_fwd']
    squeezenet0_relu1_fwd ['squeezenet0_relu1_fwd']
    squeezenet0_conv2_fwd ['squeezenet0_conv2_fwd']
    squeezenet0_relu2_fwd ['squeezenet0_relu2_fwd']
    squeezenet0_conv3_fwd ['squeezenet0_conv3_fwd']
    squeezenet0_relu3_fwd ['squeezenet0_relu3_fwd']
    squeezenet0_concat0 ['squeezenet0_concat0']
    squeezenet0_conv4_fwd ['squeezenet0_conv4_fwd']
    squeezenet0_relu4_fwd ['squeezenet0_relu4_fwd']
    squeezenet0_conv5_fwd ['squeezenet0_conv5_fwd']
    squeezenet0_relu5_fwd ['squeezenet0_relu5_fwd']
    squeezenet0_conv6_fwd ['squeezenet0_conv6_fwd']
    squeezenet0_relu6_fwd ['squeezenet0_relu6_fwd']
    squeezenet0_concat1 ['squeezenet0_concat1']
    squeezenet0_pool1_fwd ['squeezenet0_pool1_fwd']
    squeezenet0_conv7_fwd ['squeezenet0_conv7_fwd']
    squeezenet0_relu7_fwd ['squeezenet0_relu7_fwd']
    squeezenet0_conv8_fwd ['squeezenet0_conv8_fwd']
    squeezenet0_relu8_fwd ['squeezenet0_relu8_fwd']
    squeezenet0_conv9_fwd ['squeezenet0_conv9_fwd']
    squeezenet0_relu9_fwd ['squeezenet0_relu9_fwd']
    squeezenet0_concat2 ['squeezenet0_concat2']
    squeezenet0_conv10_fwd ['squeezenet0_conv10_fwd']
    squeezenet0_relu10_fwd ['squeezenet0_relu10_fwd']
    squeezenet0_conv11_fwd ['squeezenet0_conv11_fwd']
    squeezenet0_relu11_fwd ['squeezenet0_relu11_fwd']
    squeezenet0_conv12_fwd ['squeezenet0_conv12_fwd']
    squeezenet0_relu12_fwd ['squeezenet0_relu12_fwd']
    squeezenet0_concat3 ['squeezenet0_concat3']
    squeezenet0_pool2_fwd ['squeezenet0_pool2_fwd']
    squeezenet0_conv13_fwd ['squeezenet0_conv13_fwd']
    squeezenet0_relu13_fwd ['squeezenet0_relu13_fwd']
    squeezenet0_conv14_fwd ['squeezenet0_conv14_fwd']
    squeezenet0_relu14_fwd ['squeezenet0_relu14_fwd']
    squeezenet0_conv15_fwd ['squeezenet0_conv15_fwd']
    squeezenet0_relu15_fwd ['squeezenet0_relu15_fwd']
    squeezenet0_concat4 ['squeezenet0_concat4']
    squeezenet0_conv16_fwd ['squeezenet0_conv16_fwd']
    squeezenet0_relu16_fwd ['squeezenet0_relu16_fwd']
    squeezenet0_conv17_fwd ['squeezenet0_conv17_fwd']
    squeezenet0_relu17_fwd ['squeezenet0_relu17_fwd']
    squeezenet0_conv18_fwd ['squeezenet0_conv18_fwd']
    squeezenet0_relu18_fwd ['squeezenet0_relu18_fwd']
    squeezenet0_concat5 ['squeezenet0_concat5']
    squeezenet0_conv19_fwd ['squeezenet0_conv19_fwd']
    squeezenet0_relu19_fwd ['squeezenet0_relu19_fwd']
    squeezenet0_conv20_fwd ['squeezenet0_conv20_fwd']
    squeezenet0_relu20_fwd ['squeezenet0_relu20_fwd']
    squeezenet0_conv21_fwd ['squeezenet0_conv21_fwd']
    squeezenet0_relu21_fwd ['squeezenet0_relu21_fwd']
    squeezenet0_concat6 ['squeezenet0_concat6']
    squeezenet0_conv22_fwd ['squeezenet0_conv22_fwd']
    squeezenet0_relu22_fwd ['squeezenet0_relu22_fwd']
    squeezenet0_conv23_fwd ['squeezenet0_conv23_fwd']
    squeezenet0_relu23_fwd ['squeezenet0_relu23_fwd']
    squeezenet0_conv24_fwd ['squeezenet0_conv24_fwd']
    squeezenet0_relu24_fwd ['squeezenet0_relu24_fwd']
    squeezenet0_concat7 ['squeezenet0_concat7']
    squeezenet0_dropout0_fwd ['squeezenet0_dropout0_fwd']
    squeezenet0_conv25_fwd ['squeezenet0_conv25_fwd']
    squeezenet0_relu25_fwd ['squeezenet0_relu25_fwd']
    squeezenet0_pool3_fwd ['squeezenet0_pool3_fwd']
    squeezenet0_flatten0_reshape0 ['squeezenet0_flatten0_reshape0']




We select one of the last one.


.. code-block:: default


    selected = outputs[-3]
    print("selected", selected)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    selected squeezenet0_relu25_fwd




And we tell *OnnxTransformer* to use that
specific one and to flatten the output
as the dimension is not a matrix.


.. code-block:: default



    pipe2 = Pipeline(steps=[
        ('deep', OnnxTransformer(
            model_bytes, runtime='onnxruntime1', change_batch_size=0,
            output_name=selected, reshape=True)),
        ('pca', PCA(2))
    ])

    pipe2.fit(X_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Pipeline(steps=[('deep',
                     OnnxTransformer(change_batch_size=0, onnx_bytes=b'\x08\x03:\xa5\xc0\xae\x02\n\xca\x01\n\x04data\n\x18squeezenet0_conv0_weight\n\x16squeezenet0_conv0_bias\x12\x15squeezenet0_conv0_fwd\x1a\x15squeezenet0_conv0_fwd"\x04Conv*\x12\n\tdilations@\x01@\x01\xa0\x01\x07*\x0c\n\x05group\x18\x01\xa0\x01\x02*\x15\n\x0ckernel_shape@\x03@\x...zenet0_conv25_bias\x12\x0b\n\t\x08\x01\x12\x05\n\x03\x08\xe8\x07Z$\n\x16reshape_attr_tensor118\x12\n\n\x08\x08\x07\x12\x04\n\x02\x08\x02b0\n\x1dsqueezenet0_flatten0_reshape0\x12\x0f\n\r\x08\x01\x12\t\n\x02\x08\x01\n\x03\x08\xe8\x07B\x02\x10\x07', output_name='squeezenet0_relu25_fwd', reshape=True, runtime='onnxruntime1')),
                    ('pca', PCA(n_components=2))])



We check that it is different.
The following values are the shape of the
PCA components. The number of column is the number
of dimensions of the outputs of the transfered
neural network.


.. code-block:: default


    print(pipe.steps[1][1].components_.shape,
          pipe2.steps[1][1].components_.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (2, 1000) (2, 169000)




Graph again.


.. code-block:: default


    proj2 = pipe2.transform(X_train)

    fig, ax = plt.subplots(1, 1, figsize=(5, 5))
    ax.plot(proj2[:, 0], proj2[:, 1], 'o')
    ax.set_title("Second projection of classification probabilities")
    text = ["%1.0f-%s" % (el[0], el[1][0][1]) for el in climgs]
    for label, x, y in zip(text, proj2[:, 0], proj2[:, 1]):
        ax.annotate(
            label, xy=(x, y), xytext=(-10, 10), fontsize=8,
            textcoords='offset points', ha='right', va='bottom',
            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),
            arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))



.. image:: /auto_tutorial/images/sphx_glr_plot_gbegin_transfer_learning_003.png
    :alt: Second projection of classification probabilities
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  4.455 seconds)


.. _sphx_glr_download_auto_tutorial_plot_gbegin_transfer_learning.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: /../../cus/lib/python3.7/site-packages/sphinx_gallery/_static/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/microsoft/skl2onnx/master?urlpath=lab/tree/notebooks/auto_tutorial/plot_gbegin_transfer_learning.ipynb
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_gbegin_transfer_learning.py <plot_gbegin_transfer_learning.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_gbegin_transfer_learning.ipynb <plot_gbegin_transfer_learning.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
